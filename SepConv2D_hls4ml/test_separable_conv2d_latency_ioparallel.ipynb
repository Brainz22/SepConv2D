{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c74916fd-e541-44b7-81dc-7fbb987d5141",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Test `separable_conv2d`, `depthwise_conv2d`, `pointwise_conv2d` (`Latency`, `io_parallel`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41aabfa4-3c30-4ae9-868c-2faae576ed54",
   "metadata": {},
   "source": [
    "Please test it with the [sepconv-latency-ioparallel](https://github.com/fastmachinelearning/hls4ml/tree/sepconv-latency-ioparallel) branch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69d694a0-8942-41bf-ad4a-c65f08e9aabe",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5b3422-99a8-460a-9771-72bffd11f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Choose the layer to test\n",
    "#\n",
    "#LAYER = 'depthwise_conv2d' # \n",
    "#LAYER = 'pointwise_conv2d'\n",
    "LAYER = 'separable_conv2d' # uses both depthwise and pointwise\n",
    "\n",
    "RUN_HLS = True\n",
    "IO_TYPE = 'io_parallel'\n",
    "STRATEGY = 'Latency'\n",
    "BACKEND = 'Vivado'\n",
    "\n",
    "H = 5    # Input height\n",
    "W = 6    # Input width\n",
    "Din = 1  # Input # of channels\n",
    "Fh = 3   # Kernel height\n",
    "Fw = 3   # Kernel width\n",
    "Dout = 2 # Kernel # of filters\n",
    "\n",
    "B = 1   # Test set batch size\n",
    "\n",
    "FXD_W = 12 # Fixed-point precision, word bit width\n",
    "FXD_I = 11 # Fixed-point precision, integer-part bit width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b218c-bce1-4f1f-9259-cee4e46332bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings on the ASIC-group servers\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c5fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = '/home/xilinx/Vivado/2019.1/bin:' + os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c970363e-0917-4851-9f44-012363f4593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xilinx/Vivado/2019.1/bin:/home/users/russelld/micromamba/envs/sepConv2d/bin:/home/users/russelld/micromamba/condabin:/home/users/russelld/.vscode-server/bin/b3e4e68a0bc097f0ae7907b217c1119af9e03435/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b021ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['XILINX_VIVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd30aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['XILINX_VIVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6068ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/xilinx/Vivado/2021.2/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f39547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages (6.0.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48331da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff03fd9-4e69-4d76-9579-dc5b77cc256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import pyaml\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from qkeras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e4c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea5e7c9-7835-44cd-ab4c-12979590f6ae",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd8f5b11-13c2-4ab2-83e6-4353458806ff",
   "metadata": {},
   "source": [
    "### Create keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042b1846-8486-4a73-b8dc-a66d3716bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel(layer, input_shape, kernel_size, filters):\n",
    "    # # Generate the same random values\n",
    "    # import random\n",
    "    # import numpy as np\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    # random.seed(42)\n",
    "    # np.random.seed(42)\n",
    "    # tf.random.set_seed(42)\n",
    "\n",
    "    x_in = Input(input_shape, name='input_1')\n",
    "    if layer == 'depthwise_conv2d':\n",
    "        x_out = DepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif layer == 'pointwise_conv2d':\n",
    "        x_out = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=(1,1),\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = SeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            name = 'separable_conv2d'\n",
    "    )(x_in)\n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787e0e1d-a02d-42ef-87c5-bb0ed7bde87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 3, 4, 2)          11        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CreateModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11efcaf2-5b91-4e84-aaee-4d4c85891749",
   "metadata": {},
   "source": [
    "### Show keras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d68bd63-f361-41c8-9f7f-418d2fa75d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0:\n",
      "(3, 3, 1, 1)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "-----------\n",
      "Weights 1:\n",
      "(1, 1, 1, 2)\n",
      "[1. 1.]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "weights = model.get_weights()\n",
    "for i, w in enumerate(weights):\n",
    "    print(f\"Weights {i}:\")\n",
    "    print(w.shape)\n",
    "    print(w.flatten())\n",
    "    print(\"-----------\")\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f20a8e6-8ef4-4b52-b430-c5e3912f3570",
   "metadata": {},
   "source": [
    "### Show keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fadf99-7199-4a49-bdf5-80da0dc2aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='keras_model.png', show_shapes=True, show_layer_names=True, expand_nested=True)#, show_layer_activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58f4c122-5454-471e-a0a1-cb9c490cd2c5",
   "metadata": {},
   "source": [
    "### Run keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d69a59-959d-4a25-8e87-7f75294f5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "toy_data = np.random.rand(B,\n",
    "                          H,\n",
    "                          W,\n",
    "                          Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                toy_data[i][h][w][d] = h + w + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ffe386-299d-4ec4-842e-986931fcf99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]]\n",
      "\n",
      "  [[1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]]\n",
      "\n",
      "  [[2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]\n",
      "   [8.]]\n",
      "\n",
      "  [[4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]\n",
      "   [8.]\n",
      "   [9.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Show inputs\n",
    "print(toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57531c58-e069-402d-aa3b-418616f570a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10245281-c053-4950-9bd5-5b1be552dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b19812-aa59-4dea-9ec7-84c3cdcc71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hls4ml.model.profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe1e591a-2414-4ad6-a348-cfd9c66f0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "# keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, toy_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01c67209-e3a4-4ffa-b24c-69c8435f447a",
   "metadata": {},
   "source": [
    "### Show keras traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e5f673-3155-45b0-889e-ba3494073896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backup print options\n",
    "# bkp_threshold = np.get_printoptions()['threshold']\n",
    "# bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# # Set print options\n",
    "# np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "# print('-------')\n",
    "# print('input shape', toy_data.shape)\n",
    "# print('input', toy_data.flatten())\n",
    "\n",
    "# layer_names = [layer.name for layer in model.layers if not isinstance(layer, InputLayer)]\n",
    "# for layer in layer_names:\n",
    "#     print('-------')\n",
    "#     print('{} shape'.format(layer), keras_trace[layer].shape)\n",
    "#     print(layer, keras_trace[layer].flatten())\n",
    "\n",
    "# print('-------')\n",
    "\n",
    "# # Restore print options\n",
    "# np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45bb190e-45f6-4b5c-a487-7537184ac8d4",
   "metadata": {},
   "source": [
    "## QKeras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ca37c3-f930-40dd-bcc6-add8f01be09f",
   "metadata": {},
   "source": [
    "### Create qkeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be561610-0fc1-46c3-93cf-db08ff44d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateQModel(type, input_shape, kernel_size, filters):\n",
    "    # # Generate the same random values\n",
    "    # import random\n",
    "    # import numpy as np\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    # random.seed(42)\n",
    "    # np.random.seed(42)\n",
    "    # tf.random.set_seed(42)\n",
    "    \n",
    "    x_in = Input(input_shape, name='q_input_1')\n",
    "    if type == 'depthwise_conv2d':\n",
    "        x_out = QDepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif type == 'pointwise_conv2d':\n",
    "        x_out = QConv2D(\n",
    "            kernel_size=(1,1), # 1x1 convolution\n",
    "            filters=filters,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            kernel_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = QSeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            pointwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_separable_conv2d'\n",
    "        )(x_in)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a05a72da-ac08-403e-b1a0-bcebe53a3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_input_1 (InputLayer)      [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepara  (None, 3, 4, 2)          11        \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = CreateQModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "qmodel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2223b492-ca78-4bb1-9389-644a095e6035",
   "metadata": {},
   "source": [
    "### Show qkeras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232ee0dd-6caf-4524-9f64-7ba6cd9c4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0:\n",
      "(3, 3, 1, 1)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "-----------\n",
      "Weights 1:\n",
      "(1, 1, 1, 2)\n",
      "[1. 1.]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Print the weights on console\n",
    "#N_WEIGHTS = 10\n",
    "\n",
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "qweights = qmodel.get_weights()\n",
    "for i, w in enumerate(qweights):\n",
    "    print(f\"Weights {i}:\")\n",
    "    print(w.shape)\n",
    "    #print(w)\n",
    "    print(w.flatten())\n",
    "    print(\"-----------\")\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b041e0a7-8be7-43ee-93de-716ca2391be9",
   "metadata": {},
   "source": [
    "### Show qkeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1962999-bbc5-4e2a-9da5-0d6b91c474a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(qmodel, to_file='qkeras_model.png', show_shapes=True, show_layer_names=True, expand_nested=True)#, show_layer_activations=True)\n",
    "#import hls4ml\n",
    "#hls4ml.utils.plot.plot_model(qmodel, show_layer_names=True, show_precision=False, show_shapes=True, to_file='qkeras_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6831aa7-206a-4735-961f-6f233f5e8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/estimate.py:345: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/estimate.py:345: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of operations in model:\n",
      "    q_separable_conv2d            : 132   (smult_12_8)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_8                    : 132\n",
      "\n",
      "Weight profiling:\n",
      "    q_separable_conv2d_weights_0   : 9     (12-bit unit)\n",
      "    q_separable_conv2d_weights_1   : 2     (12-bit unit)\n",
      "    q_separable_conv2d_bias        : 0     (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    q_separable_conv2d             : 0.0000\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_qstats(qmodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f44f1bf-3549-40e6-a32d-052e79847d96",
   "metadata": {},
   "source": [
    "## hls4ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b60e5bb3-cfbe-45e5-92ca-a312d4b230c6",
   "metadata": {},
   "source": [
    "### Configure hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52098a4a-17db-48e7-a872-55de8908407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/russelld/SepConv2D_hls4ml/hls4ml/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml.utils\n",
    "import hls4ml.converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f62ee5a-b7b8-4d57-b49d-a4e099b3ac38",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    qmodel, \n",
    "    granularity='name',\n",
    "    default_precision='fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    ")\n",
    "config['LayerName']['q_input_1']['Precision']['result'] = 'fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    "\n",
    "config['Model']['Strategy'] = STRATEGY\n",
    "#config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel, \n",
    "    hls_config=config, \n",
    "    output_dir='{}_{}_{}_{}_notrace_hls4ml_prj'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), \n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    backend=BACKEND,\n",
    "    io_type=IO_TYPE\n",
    ")\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f40ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6752fc96-46de-48c8-9127-61251fd5bb0c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(pyaml.dump(config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dfb700-10ec-4ac3-8c4d-0238edf15243",
   "metadata": {},
   "source": [
    "### Run qkeras and hls4ml simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c929e0-4690-4558-87d4-b74cdd02c9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing for layer: q_input_1\n",
      "Enable tracing for layer: q_separable_conv2d\n",
      "Enable tracing for layer: q_separable_conv2d_linear\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "toy_data = np.random.rand(B,H,W,Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                toy_data[i][h][w][d] = h + w + d\n",
    "\n",
    "q_toy_data = quantized_bits(FXD_W, FXD_I-1, alpha=1)(toy_data).numpy()\n",
    "\n",
    "# Enable tracing for all of the layers\n",
    "for layer in config['LayerName'].keys():\n",
    "    print('Enable tracing for layer:', layer)\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "hmodel = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel,\n",
    "    hls_config=config,\n",
    "    output_dir='{}_{}_{}_{}_trace_hls4ml_prj'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()),\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    io_type=IO_TYPE,\n",
    ")\n",
    "hmodel.compile()\n",
    "\n",
    "# Run tracing on the test set for the hls4ml model (fixed-point precision) \n",
    "#hls4ml_pred, hls4ml_trace = hmodel.trace(q_toy_data)\n",
    "\n",
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "#keras_trace = hls4ml.model.profiling.get_ymodel_keras(qmodel, q_toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d67e2a8-eb85-4887-8952-0271728f5304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vivado_separable_conv2d_latency_io_parallel_trace_hls4ml_prj'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}_{}_{}_{}_trace_hls4ml_prj'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f85f5c7d-c4ef-4a72-9d64-71468efe3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(keras_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fcd592b-38f6-4d2e-b903-ead511b12a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save inputs and expected outputs for further debugging\n",
    "# with open('{}_{}_{}_{}_trace_hls4ml_prj/tb_data/tb_input_features.dat'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), 'w') as f:\n",
    "#     f.write(' '.join(map(str, toy_data[0].flatten())))\n",
    "# with open('{}_{}_{}_{}_trace_hls4ml_prj/tb_data/tb_output_predictions.dat'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), 'w') as f:\n",
    "#     f.write(' '.join(map(str, keras_trace['q_{}'.format(LAYER)][0].flatten())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c658a3-8bcf-44df-8c9d-a9a6a762b4d2",
   "metadata": {},
   "source": [
    "### Show qkeras and hls4ml traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f635be40-5546-4ad9-bea9-64e73321918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the traces on console\n",
    "# N_ELEMENTS=10\n",
    "\n",
    "# # Backup print options\n",
    "# bkp_threshold = np.get_printoptions()['threshold']\n",
    "# bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# # Set print options\n",
    "# np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "# print('input', q_toy_data.flatten())\n",
    "# for key in hls4ml_trace.keys():\n",
    "#     print('-------')\n",
    "#     print(key, hls4ml_trace[key].shape)\n",
    "#     print('[qkeras]', key, keras_trace[key].flatten())\n",
    "#     print('[hls4ml]', key, hls4ml_trace[key].flatten())\n",
    "\n",
    "# #print(hls4ml_trace)\n",
    "# # Restore print options\n",
    "# np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "694ef0d7-7af8-42fd-848f-afe57892d279",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot correlation qkeras and hls4ml (Fails because of keras_trace rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc91078-5827-4ae8-a95e-d4208078051a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate correlation plots\n",
    "# for layer in hls4ml_trace.keys():\n",
    "#     print(layer)\n",
    "#     if '_alpha' in layer:\n",
    "#         continue\n",
    "#     plt.figure()\n",
    "#     klayer = layer\n",
    "#     if '_linear' in layer:\n",
    "#         klayer = layer.replace('_linear', '')\n",
    "#     plt.scatter(hls4ml_trace[layer].flatten(), keras_trace[klayer].flatten(), s=0.2)\n",
    "#     min_x = min(np.amin(hls4ml_trace[layer]), np.amin(keras_trace[klayer]))\n",
    "#     max_x = max(np.amax(hls4ml_trace[layer]), np.amax(keras_trace[klayer]))\n",
    "#     plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "#     plt.xlabel('hls4ml {}'.format(layer))\n",
    "#     plt.ylabel('QKeras {}'.format(klayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "379c9632-898f-4b03-b29f-a93fe53b67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(B,H,W,Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                x[i][h][w][d] = h + w + d\n",
    "\n",
    "q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1af3f7d-c35c-4f37-b7a4-6b66b5b26ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.]],\n",
       "\n",
       "        [[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.]],\n",
       "\n",
       "        [[2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.]],\n",
       "\n",
       "        [[3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.]],\n",
       "\n",
       "        [[4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dbe2ad5-96e3-4cd1-8491-d6778a43568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hmodel.predict(q_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "007f6c10-90ee-47e6-9c11-c91b22b17246",
   "metadata": {},
   "source": [
    "### Run HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b4a4e2-7250-469e-8ae4-0cbf6161dc8f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_model(keras_model,\n",
    "                  layer='layer_undef',\n",
    "                  strategy='Latency',\n",
    "                  io_type='io_stream',\n",
    "                  hls_backend='Vivado',\n",
    "                  fpga_part='xcu250-figd2104-2L-e',\n",
    "                  output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\n",
    "                 ):\n",
    "\n",
    "    yaml_config = hls4ml.backends.get_backend(hls_backend).create_initial_config(\n",
    "        part=fpga_part, \n",
    "        io_type=io_type,\n",
    "    )\n",
    "    # or whatever part you want to use\n",
    "    yaml_config['Backend'] = hls_backend\n",
    "\n",
    "    yaml_config['ProjectName'] = 'smartpixels'\n",
    "    config = hls4ml.utils.config_from_keras_model(keras_model, granularity='name', default_precision='fixed<{},{}>'.format(FXD_W, FXD_I))\n",
    "    config['LayerName']['q_input_1']['Precision']['result'] = 'fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    "    \n",
    "    config['Model']['Strategy'] = strategy\n",
    "    \n",
    "    yaml_config['HLSConfig'] = config\n",
    "\n",
    "    if io_type == 'io_stream' and hls_backend == 'Vivado':\n",
    "        hls4ml.model.optimizer.get_optimizer('vivado:fifo_depth_optimization').configure(profiling_fifo_depth=100_000)\n",
    "        yaml_config['HLSConfig']['Flows'] = ['vivado:fifo_depth_optimization']\n",
    "\n",
    "    yaml_config['KerasModel'] = keras_model\n",
    "    yaml_config['OutputDir'] = output_dir.format(hls_backend.lower(), layer.lower(), strategy.lower(), io_type.lower(), fpga_part.lower())\n",
    "\n",
    "    # At this point you should verify that the yaml matches the one you already have (check the output directory of the existing project)\n",
    "\n",
    "    # About 10 samples should be enough, don't put a lot since you'll wait **A LOT** of time to simulate through them\n",
    "    x = np.random.rand(B,H,W,Din)\n",
    "\n",
    "    for i in range(B):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                for d in range(Din):\n",
    "                    x[i][h][w][d] = h + w + d\n",
    "\n",
    "    q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(x).numpy()\n",
    "\n",
    "    #q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(np.random.rand(B,H,W,Din)).numpy() # or whatever the input is\n",
    "\n",
    "    from pathlib import Path\n",
    "    Path(yaml_config['OutputDir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # We need both samples and predictions passed to the testbench for cosim to do meaningful stuff\n",
    "\n",
    "    input_data = ''\n",
    "    for sample in q_x:\n",
    "        for val in sample.flatten():\n",
    "            input_data += str(val) + ' '\n",
    "        input_data += '\\n'\n",
    "\n",
    "    input_data_path = yaml_config['OutputDir'] + '/input_data.dat'\n",
    "\n",
    "    with open(input_data_path, 'w') as f:\n",
    "        f.write(input_data.rstrip())\n",
    "    yaml_config['InputData'] = input_data_path\n",
    "\n",
    "    y = keras_model.predict(q_x)\n",
    "    output_data = ''\n",
    "    for prediction in y:\n",
    "        for val in prediction.flatten():\n",
    "            output_data += str(val) + ' '\n",
    "        output_data += '\\n'\n",
    "\n",
    "    output_data_path = yaml_config['OutputDir'] + '/output_data.dat'\n",
    "    with open(output_data_path, 'w') as f:\n",
    "        f.write(output_data.rstrip())\n",
    "    yaml_config['OutputPredictions'] = output_data_path\n",
    "\n",
    "    model = hls4ml.converters.keras_to_hls(yaml_config)\n",
    "    model.write()\n",
    "\n",
    "    # reset=True will nuke any existing synthesis, use with care\n",
    "    report = model.build(csim=False, synth=True, cosim=True, validation=False, export=True, vsynth=True, reset=True)\n",
    "    #report = model.build(csim=False, synth=False, cosim=False, validation=False, export=False, vsynth=False, reset=False)\n",
    "    report.pop('CSimResults', None) # We don't care about this, and it spams the output\n",
    "    report.pop('CosimResults', None)\n",
    "    print(report) # Print hashmap\n",
    "    return report, fpga_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a7eaed8-bd0f-4abd-a8d8-604081b7ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    return result.stdout, result.stderr\n",
    "\n",
    "def print_report(report, fpga_part = '?', vivado_version = '?', knobs = {}, hls = True, syn = True, cosim = True):\n",
    "    hls_results = report['CSynthesisReport']\n",
    "    syn_results = report['VivadoSynthReport']\n",
    "    cosim_results = report['CosimReport']\n",
    "    if hls:\n",
    "        print('-----------------------------------')\n",
    "        print('Vivado version: {}'.format(vivado_version))\n",
    "        print('FPGA part:      {}'.format(fpga_part))\n",
    "        print('Knobs:          {}'.format(knobs))\n",
    "        print('-----------------------------------')\n",
    "        print('HLS')\n",
    "        print('Target Clock Period:    {} ns'.format(hls_results['TargetClockPeriod']))\n",
    "        print('Estimated Clock Period: {} ns'.format(hls_results['EstimatedClockPeriod']))\n",
    "        print('Best/Worst Latency: {} / {}'.format(hls_results['BestLatency'], hls_results['WorstLatency']))\n",
    "        print('Interval Min/Max:   {} / {}'.format(hls_results['IntervalMin'], hls_results['IntervalMax']))\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(hls_results['BRAM_18K'], float(hls_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(hls_results['DSP'], float(hls_results['DSP'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(hls_results['FF'], float(hls_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(hls_results['LUT'], float(hls_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "        #print(\"URAM:                   {}, {} (Aval. {})\".format(hls_results['URAM'], int(hls_results['URAM'])*100.0/int(hls_results['AvailableURAM']), hls_results['AvailableURAM']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Synthesis')\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(syn_results['BRAM_18K'], float(syn_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(syn_results['DSP48E'], float(syn_results['DSP48E'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(syn_results['FF'], float(syn_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(syn_results['LUT'], float(syn_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Cosimulation')\n",
    "        print('Max/Min Latency:    {} / {}'.format(cosim_results['LatencyMax'], cosim_results['LatencyMin']))\n",
    "        print('Avg Latency:        {}'.format(cosim_results['LatencyAvg']))\n",
    "        print('Max/Min Interval:   {} / {}'.format(cosim_results['IntervalMax'], cosim_results['IntervalMin']))\n",
    "        print('Avg Interval:       {}'.format(cosim_results['IntervalAvg']))\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceec8e72-5a45-412b-a655-57b0d3c0d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = run_command('vivado -version')\n",
    "vivado_version = stdout.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b17a91a6-37d5-4874-96a0-d06b6db5faff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_HLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6de40a5-05c5-4dfd-a2b6-8bf8e6be257f",
   "metadata": {},
   "source": [
    "### Run synthesis for Alveo U250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d13bc4b4-3f05-4650-a969-95e6589ac93b",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/q_separable_conv2d/separable_conv2d/depthwise' defined at (most recent call last):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1231580/1890756911.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', \"if (RUN_HLS):\\n    report, fpga_part = convert_model(qmodel,                                    \\n                                      layer=LAYER,\\n                                      strategy=STRATEGY,\\n                                      io_type=IO_TYPE,\\n                                      hls_backend=BACKEND,\\n                                      fpga_part='xcu250-figd2104-2L-e',\\n                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\\n                                     )\\n\")\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2517, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1340, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_1231580/1244092923.py\", line 64, in convert_model\n      y = keras_model.predict(q_x)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/qconvolutional.py\", line 804, in call\n      outputs = tf.keras.backend.separable_conv2d(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/backend.py\", line 6263, in separable_conv2d\n      x = tf.compat.v1.nn.separable_conv2d(\nNode: 'model_1/q_separable_conv2d/separable_conv2d/depthwise'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=1}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=1,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng6{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=2,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=0,k4=1,k5=1,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng3{k11=2}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n\t [[{{node model_1/q_separable_conv2d/separable_conv2d/depthwise}}]] [Op:__inference_predict_function_655]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[38], line 64\u001b[0m, in \u001b[0;36mconvert_model\u001b[0;34m(keras_model, layer, strategy, io_type, hls_backend, fpga_part, output_dir)\u001b[0m\n\u001b[1;32m     61\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(input_data\u001b[38;5;241m.\u001b[39mrstrip())\n\u001b[1;32m     62\u001b[0m yaml_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputData\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_data_path\n\u001b[0;32m---> 64\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m y:\n",
      "File \u001b[0;32m~/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/q_separable_conv2d/separable_conv2d/depthwise' defined at (most recent call last):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1231580/1890756911.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', \"if (RUN_HLS):\\n    report, fpga_part = convert_model(qmodel,                                    \\n                                      layer=LAYER,\\n                                      strategy=STRATEGY,\\n                                      io_type=IO_TYPE,\\n                                      hls_backend=BACKEND,\\n                                      fpga_part='xcu250-figd2104-2L-e',\\n                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\\n                                     )\\n\")\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2517, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1340, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_1231580/1244092923.py\", line 64, in convert_model\n      y = keras_model.predict(q_x)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/qconvolutional.py\", line 804, in call\n      outputs = tf.keras.backend.separable_conv2d(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/backend.py\", line 6263, in separable_conv2d\n      x = tf.compat.v1.nn.separable_conv2d(\nNode: 'model_1/q_separable_conv2d/separable_conv2d/depthwise'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=1}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=1,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng6{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=2,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=0,k4=1,k5=1,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng3{k11=2}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n\t [[{{node model_1/q_separable_conv2d/separable_conv2d/depthwise}}]] [Op:__inference_predict_function_655]"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if (RUN_HLS):\n",
    "    report, fpga_part = convert_model(qmodel,                                    \n",
    "                                      layer=LAYER,\n",
    "                                      strategy=STRATEGY,\n",
    "                                      io_type=IO_TYPE,\n",
    "                                      hls_backend=BACKEND,\n",
    "                                      fpga_part='xcu250-figd2104-2L-e',\n",
    "                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95e80636-250f-452b-8b34-f48267654919",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (RUN_HLS):\n\u001b[0;32m----> 2\u001b[0m     print_report(\u001b[43mreport\u001b[49m,\n\u001b[1;32m      3\u001b[0m                  fpga_part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxcu250-figd2104-2L-e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                  vivado_version\u001b[38;5;241m=\u001b[39mvivado_version,\n\u001b[1;32m      5\u001b[0m                  knobs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m : BACKEND, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m :LAYER, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mio_type\u001b[39m\u001b[38;5;124m'\u001b[39m : IO_TYPE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m : STRATEGY}\n\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "if (RUN_HLS):\n",
    "    print_report(report,\n",
    "                 fpga_part='xcu250-figd2104-2L-e',\n",
    "                 vivado_version=vivado_version,\n",
    "                 knobs = {'backend' : BACKEND, 'layer' :LAYER, 'io_type' : IO_TYPE, 'strategy' : STRATEGY}\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39105976-e390-4fa5-9d2d-3825e1df1180",
   "metadata": {},
   "source": [
    "#### Previous results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cf624a1-a512-408b-8b7b-dfc0d763fb8f",
   "metadata": {},
   "source": [
    "##### `depthwise_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6de1736-7518-4f70-bb6b-e88dfc2e3c5a",
   "metadata": {},
   "source": [
    "```\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'depthwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.271 ns\n",
    "Best/Worst Latency: 5 / 6\n",
    "Interval Min/Max:   3 / 3\n",
    "BRAM_18K:           10, 0.2% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 721, 0.0% (Aval. 3456000)\n",
    "LUT:                39898, 2.3% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 1271, 0.0% (Aval. 3456000)\n",
    "LUT:                1628, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    6 / 6\n",
    "Avg Latency:        6.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a87b21-315d-4ff9-beb0-2e84bd82dafa",
   "metadata": {},
   "source": [
    "##### `pointwise_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b65250-b927-4cfb-a93f-cdfdd581177f",
   "metadata": {},
   "source": [
    "```\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'pointwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "Notes:          It uses conv2d\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.225 ns\n",
    "Best/Worst Latency: 59 / 60\n",
    "Interval Min/Max:   60 / 60\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 1151, 0.0% (Aval. 3456000)\n",
    "LUT:                1387, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 489, 0.0% (Aval. 3456000)\n",
    "LUT:                601, 0.0% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    60 / 60\n",
    "Avg Latency:        60.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'pointwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "Notes:          Custom pointwise, optimized\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 2.679 ns\n",
    "Best/Worst Latency: 4 / 5\n",
    "Interval Min/Max:   5 / 5\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 726, 0.0% (Aval. 3456000)\n",
    "LUT:                10091, 0.6% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 377, 0.0% (Aval. 3456000)\n",
    "LUT:                867, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    5 / 5\n",
    "Avg Latency:        5.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56c776ec-8f89-43a0-b857-654c2e529734",
   "metadata": {},
   "source": [
    "##### `separable_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3022d54a-347e-476d-aecf-efc72353d589",
   "metadata": {},
   "source": [
    "csim works, but HLS fails\n",
    "```\n",
    "ERROR: [HLS 200-70] Compilation errors found: In file included from firmware/smartpixels.cpp:1:\n",
    "firmware/smartpixels.cpp:35:2: error: no matching function for call to 'separable_conv_2d_cl'\n",
    " nnet::separable_conv_2d_cl<input_t, q_separable_conv2d_dw_out_t, result_t, config2>(q_input_1, layer2_out, d2, p2, z2, b2);\n",
    " ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "firmware/nnet_utils/nnet_sepconv2d_stream.h:122:6: note: candidate function [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2] not viable: no known conversion from 'input_t *' (aka 'ap_fixed<12, 11> *') to 'hls::stream<ap_fixed<12, 11, 5, 3, 0> > &' for 1st argument; \n",
    "void separable_conv_2d_cl(hls::stream<data_T> &data, hls::stream<res_T> &res,\n",
    "     ^\n",
    "firmware/nnet_utils/nnet_sepconv2d.h:51:6: note: candidate template ignored: substitution failure [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2]\n",
    "void separable_conv_2d_cl(\n",
    "     ^\n",
    "1 error generated.\n",
    "Failed during preprocessing.\n",
    "    while executing\n",
    "\"source build_prj.tcl\"\n",
    "    (\"uplevel\" body line 1)\n",
    "    invoked from within\n",
    "\"uplevel \\#0 [list source $arg] \"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d4cf5be-9005-4237-bc70-a892908f1a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /home/xilinx/Vivado/2019.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/home/xilinx/Vivado/2019.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'russelld' on host 'scully.physics.ucsd.edu' (Linux_x86_64 version 4.18.0-348.12.2.el8_5.x86_64) on Sat Dec 02 00:33:31 PST 2023\n",
      "INFO: [HLS 200-10] In directory '/home/users/russelld/SepConv2D_hls4ml/vivado_separable_conv2d_latency_io_parallel_notrace_hls4ml_prj'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/users/russelld/SepConv2D_hls4ml/vivado_separable_conv2d_latency_io_parallel_notrace_hls4ml_prj/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/users/russelld/SepConv2D_hls4ml/vivado_separable_conv2d_latency_io_parallel_notrace_hls4ml_prj/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcu250-figd2104-2L-e'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "ERROR: [HLS 200-70] Compilation errors found: In file included from firmware/myproject.cpp:1:\n",
      "firmware/myproject.cpp:35:2: error: no matching function for call to 'separable_conv_2d_cl'\n",
      " nnet::separable_conv_2d_cl<input_t, q_separable_conv2d_dw_out_t, result_t, config2>(q_input_1, layer2_out, d2, p2, z2, b2);\n",
      " ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "firmware/nnet_utils/nnet_sepconv2d_stream.h:122:6: note: candidate function [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2] not viable: no known conversion from 'input_t *' (aka 'ap_fixed<12, 11> *') to 'hls::stream<ap_fixed<12, 11, 5, 3, 0> > &' for 1st argument; \n",
      "void separable_conv_2d_cl(hls::stream<data_T> &data, hls::stream<res_T> &res,\n",
      "     ^\n",
      "firmware/nnet_utils/nnet_sepconv2d.h:58:6: note: candidate template ignored: substitution failure [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2]\n",
      "void separable_conv_2d_cl(\n",
      "     ^\n",
      "1 error generated.\n",
      "Failed during preprocessing.\n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Sat Dec  2 00:33:34 2023...\n",
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1be8a-f987-43bd-95eb-72b9afe37657",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('/home/users/russelld/SepConv2D_hls4ml/vivado_separable_conv2d_latency_io_parallel_trace_hls4ml_prj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2df635-30de-43ae-9ed0-ebe2c2e44e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
