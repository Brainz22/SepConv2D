{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c74916fd-e541-44b7-81dc-7fbb987d5141",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Test `separable_conv2d`, `depthwise_conv2d`, `pointwise_conv2d` (`Latency`, `io_parallel`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41aabfa4-3c30-4ae9-868c-2faae576ed54",
   "metadata": {},
   "source": [
    "Please test it with the [sepconv-latency-ioparallel](https://github.com/fastmachinelearning/hls4ml/tree/sepconv-latency-ioparallel) branch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69d694a0-8942-41bf-ad4a-c65f08e9aabe",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5b3422-99a8-460a-9771-72bffd11f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Choose the layer to test\n",
    "#\n",
    "LAYER = 'depthwise_conv2d' # \n",
    "#LAYER = 'pointwise_conv2d'\n",
    "#LAYER = 'separable_conv2d' # uses both depthwise and pointwise\n",
    "\n",
    "RUN_HLS = True\n",
    "IO_TYPE = 'io_parallel'\n",
    "STRATEGY = 'Latency'\n",
    "BACKEND = 'Vivado'\n",
    "\n",
    "H = 5    # Input height\n",
    "W = 6    # Input width\n",
    "Din = 1  # Input # of channels\n",
    "Fh = 3   # Kernel height\n",
    "Fw = 3   # Kernel width\n",
    "Dout = 2 # Kernel # of filters\n",
    "\n",
    "B = 1   # Test set batch size\n",
    "\n",
    "FXD_W = 12 # Fixed-point precision, word bit width\n",
    "FXD_I = 11 # Fixed-point precision, integer-part bit width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b218c-bce1-4f1f-9259-cee4e46332bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings on the ASIC-group servers\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c5fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = '/home/xilinx/Vivado/2019.1/bin:' + os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c970363e-0917-4851-9f44-012363f4593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xilinx/Vivado/2019.1/bin:/home/users/russelld/micromamba/envs/sepConv2d/bin:/home/users/russelld/micromamba/condabin:/home/users/russelld/.vscode-server/bin/b3e4e68a0bc097f0ae7907b217c1119af9e03435/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b021ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['XILINX_VIVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd30aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['XILINX_VIVADO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6068ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/xilinx/Vivado/2021.2/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f39547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages (6.0.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48331da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff03fd9-4e69-4d76-9579-dc5b77cc256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import pyaml\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from qkeras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e4c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea5e7c9-7835-44cd-ab4c-12979590f6ae",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd8f5b11-13c2-4ab2-83e6-4353458806ff",
   "metadata": {},
   "source": [
    "### Create keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042b1846-8486-4a73-b8dc-a66d3716bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateModel(layer, input_shape, kernel_size, filters):\n",
    "    # # Generate the same random values\n",
    "    # import random\n",
    "    # import numpy as np\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    # random.seed(42)\n",
    "    # np.random.seed(42)\n",
    "    # tf.random.set_seed(42)\n",
    "\n",
    "    x_in = Input(input_shape, name='input_1')\n",
    "    if layer == 'depthwise_conv2d':\n",
    "        x_out = DepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif layer == 'pointwise_conv2d':\n",
    "        x_out = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=(1,1),\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = SeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            name = 'separable_conv2d'\n",
    "    )(x_in)\n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787e0e1d-a02d-42ef-87c5-bb0ed7bde87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 3, 4, 1)          9         \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CreateModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11efcaf2-5b91-4e84-aaee-4d4c85891749",
   "metadata": {},
   "source": [
    "### Show keras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d68bd63-f361-41c8-9f7f-418d2fa75d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0:\n",
      "(3, 3, 1, 1)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "weights = model.get_weights()\n",
    "for i, w in enumerate(weights):\n",
    "    print(f\"Weights {i}:\")\n",
    "    print(w.shape)\n",
    "    print(w.flatten())\n",
    "    print(\"-----------\")\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f20a8e6-8ef4-4b52-b430-c5e3912f3570",
   "metadata": {},
   "source": [
    "### Show keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fadf99-7199-4a49-bdf5-80da0dc2aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='keras_model.png', show_shapes=True, show_layer_names=True, expand_nested=True)#, show_layer_activations=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58f4c122-5454-471e-a0a1-cb9c490cd2c5",
   "metadata": {},
   "source": [
    "### Run keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d69a59-959d-4a25-8e87-7f75294f5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "toy_data = np.random.rand(B,\n",
    "                          H,\n",
    "                          W,\n",
    "                          Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                toy_data[i][h][w][d] = h + w + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ffe386-299d-4ec4-842e-986931fcf99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]]\n",
      "\n",
      "  [[1.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]]\n",
      "\n",
      "  [[2.]\n",
      "   [3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]\n",
      "   [8.]]\n",
      "\n",
      "  [[4.]\n",
      "   [5.]\n",
      "   [6.]\n",
      "   [7.]\n",
      "   [8.]\n",
      "   [9.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Show inputs\n",
    "print(toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57531c58-e069-402d-aa3b-418616f570a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10245281-c053-4950-9bd5-5b1be552dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b19812-aa59-4dea-9ec7-84c3cdcc71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hls4ml.model.profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe1e591a-2414-4ad6-a348-cfd9c66f0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "# keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, toy_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01c67209-e3a4-4ffa-b24c-69c8435f447a",
   "metadata": {},
   "source": [
    "### Show keras traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e5f673-3155-45b0-889e-ba3494073896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backup print options\n",
    "# bkp_threshold = np.get_printoptions()['threshold']\n",
    "# bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# # Set print options\n",
    "# np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "# print('-------')\n",
    "# print('input shape', toy_data.shape)\n",
    "# print('input', toy_data.flatten())\n",
    "\n",
    "# layer_names = [layer.name for layer in model.layers if not isinstance(layer, InputLayer)]\n",
    "# for layer in layer_names:\n",
    "#     print('-------')\n",
    "#     print('{} shape'.format(layer), keras_trace[layer].shape)\n",
    "#     print(layer, keras_trace[layer].flatten())\n",
    "\n",
    "# print('-------')\n",
    "\n",
    "# # Restore print options\n",
    "# np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45bb190e-45f6-4b5c-a487-7537184ac8d4",
   "metadata": {},
   "source": [
    "## QKeras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ca37c3-f930-40dd-bcc6-add8f01be09f",
   "metadata": {},
   "source": [
    "### Create qkeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be561610-0fc1-46c3-93cf-db08ff44d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateQModel(type, input_shape, kernel_size, filters):\n",
    "    # # Generate the same random values\n",
    "    # import random\n",
    "    # import numpy as np\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    # random.seed(42)\n",
    "    # np.random.seed(42)\n",
    "    # tf.random.set_seed(42)\n",
    "    \n",
    "    x_in = Input(input_shape, name='q_input_1')\n",
    "    if type == 'depthwise_conv2d':\n",
    "        x_out = QDepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif type == 'pointwise_conv2d':\n",
    "        x_out = QConv2D(\n",
    "            kernel_size=(1,1), # 1x1 convolution\n",
    "            filters=filters,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            kernel_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = QSeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            pointwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_separable_conv2d'\n",
    "        )(x_in)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a05a72da-ac08-403e-b1a0-bcebe53a3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_input_1 (InputLayer)      [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " q_depthwise_conv2d (QDepthw  (None, 3, 4, 1)          9         \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = CreateQModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "qmodel.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2223b492-ca78-4bb1-9389-644a095e6035",
   "metadata": {},
   "source": [
    "### Show qkeras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232ee0dd-6caf-4524-9f64-7ba6cd9c4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0:\n",
      "(3, 3, 1, 1)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Print the weights on console\n",
    "#N_WEIGHTS = 10\n",
    "\n",
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "qweights = qmodel.get_weights()\n",
    "for i, w in enumerate(qweights):\n",
    "    print(f\"Weights {i}:\")\n",
    "    print(w.shape)\n",
    "    #print(w)\n",
    "    print(w.flatten())\n",
    "    print(\"-----------\")\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b041e0a7-8be7-43ee-93de-716ca2391be9",
   "metadata": {},
   "source": [
    "### Show qkeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1962999-bbc5-4e2a-9da5-0d6b91c474a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(qmodel, to_file='qkeras_model.png', show_shapes=True, show_layer_names=True, expand_nested=True)#, show_layer_activations=True)\n",
    "#import hls4ml\n",
    "#hls4ml.utils.plot.plot_model(qmodel, show_layer_names=True, show_precision=False, show_shapes=True, to_file='qkeras_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6831aa7-206a-4735-961f-6f233f5e8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/estimate.py:345: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/estimate.py:345: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of operations in model:\n",
      "    q_depthwise_conv2d            : 108   (smult_12_8)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_12_8                    : 108\n",
      "\n",
      "Weight profiling:\n",
      "    q_depthwise_conv2d_weights     : 9     (12-bit unit)\n",
      "    q_depthwise_conv2d_bias        : 0     (12-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    q_depthwise_conv2d             : 0.0000\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_qstats(qmodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f44f1bf-3549-40e6-a32d-052e79847d96",
   "metadata": {},
   "source": [
    "## hls4ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b60e5bb3-cfbe-45e5-92ca-a312d4b230c6",
   "metadata": {},
   "source": [
    "### Configure hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52098a4a-17db-48e7-a872-55de8908407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/russelld/SepConv2D_hls4ml/hls4ml/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml.utils\n",
    "import hls4ml.converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f62ee5a-b7b8-4d57-b49d-a4e099b3ac38",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_depthwise_conv2d, layer type: QDepthwiseConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 1]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_depthwise_conv2d, layer type: QDepthwiseConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 1]\n",
      "Creating HLS model\n",
      "WARNING: Layer q_depthwise_conv2d requires \"dataflow\" pipeline style. Switching to \"dataflow\" pipeline style.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    qmodel, \n",
    "    granularity='name',\n",
    "    default_precision='fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    ")\n",
    "config['LayerName']['q_input_1']['Precision']['result'] = 'fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    "\n",
    "config['Model']['Strategy'] = STRATEGY\n",
    "#config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel, \n",
    "    hls_config=config, \n",
    "    output_dir='{}_{}_{}_{}_notrace_hls4ml_prj'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), \n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    backend=BACKEND,\n",
    "    io_type=IO_TYPE\n",
    ")\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f40ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6752fc96-46de-48c8-9127-61251fd5bb0c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(pyaml.dump(config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dfb700-10ec-4ac3-8c4d-0238edf15243",
   "metadata": {},
   "source": [
    "### Run qkeras and hls4ml simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c929e0-4690-4558-87d4-b74cdd02c9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing for layer: q_input_1\n",
      "Enable tracing for layer: q_depthwise_conv2d\n",
      "Enable tracing for layer: q_depthwise_conv2d_linear\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_depthwise_conv2d, layer type: QDepthwiseConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 1]\n",
      "Creating HLS model\n",
      "WARNING: Layer q_depthwise_conv2d requires \"dataflow\" pipeline style. Switching to \"dataflow\" pipeline style.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "toy_data = np.random.rand(B,H,W,Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                toy_data[i][h][w][d] = h + w + d\n",
    "\n",
    "q_toy_data = quantized_bits(FXD_W, FXD_I-1, alpha=1)(toy_data).numpy()\n",
    "\n",
    "# Enable tracing for all of the layers\n",
    "for layer in config['LayerName'].keys():\n",
    "    print('Enable tracing for layer:', layer)\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "hmodel = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel,\n",
    "    hls_config=config,\n",
    "    output_dir='{}_{}_{}_{}_trace_hls4ml_prj'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()),\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    io_type=IO_TYPE,\n",
    ")\n",
    "hmodel.compile()\n",
    "\n",
    "# Run tracing on the test set for the hls4ml model (fixed-point precision) \n",
    "#hls4ml_pred, hls4ml_trace = hmodel.trace(q_toy_data)\n",
    "\n",
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "#keras_trace = hls4ml.model.profiling.get_ymodel_keras(qmodel, q_toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f85f5c7d-c4ef-4a72-9d64-71468efe3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(keras_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fcd592b-38f6-4d2e-b903-ead511b12a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save inputs and expected outputs for further debugging\n",
    "# with open('{}_{}_{}_{}_trace_hls4ml_prj/tb_data/tb_input_features.dat'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), 'w') as f:\n",
    "#     f.write(' '.join(map(str, toy_data[0].flatten())))\n",
    "# with open('{}_{}_{}_{}_trace_hls4ml_prj/tb_data/tb_output_predictions.dat'.format(BACKEND.lower(), LAYER.lower(), STRATEGY.lower(), IO_TYPE.lower()), 'w') as f:\n",
    "#     f.write(' '.join(map(str, keras_trace['q_{}'.format(LAYER)][0].flatten())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c658a3-8bcf-44df-8c9d-a9a6a762b4d2",
   "metadata": {},
   "source": [
    "### Show qkeras and hls4ml traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f635be40-5546-4ad9-bea9-64e73321918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the traces on console\n",
    "# N_ELEMENTS=10\n",
    "\n",
    "# # Backup print options\n",
    "# bkp_threshold = np.get_printoptions()['threshold']\n",
    "# bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# # Set print options\n",
    "# np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "# print('input', q_toy_data.flatten())\n",
    "# for key in hls4ml_trace.keys():\n",
    "#     print('-------')\n",
    "#     print(key, hls4ml_trace[key].shape)\n",
    "#     print('[qkeras]', key, keras_trace[key].flatten())\n",
    "#     print('[hls4ml]', key, hls4ml_trace[key].flatten())\n",
    "\n",
    "# #print(hls4ml_trace)\n",
    "# # Restore print options\n",
    "# np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "694ef0d7-7af8-42fd-848f-afe57892d279",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot correlation qkeras and hls4ml (Fails because of keras_trace rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffc91078-5827-4ae8-a95e-d4208078051a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate correlation plots\n",
    "# for layer in hls4ml_trace.keys():\n",
    "#     print(layer)\n",
    "#     if '_alpha' in layer:\n",
    "#         continue\n",
    "#     plt.figure()\n",
    "#     klayer = layer\n",
    "#     if '_linear' in layer:\n",
    "#         klayer = layer.replace('_linear', '')\n",
    "#     plt.scatter(hls4ml_trace[layer].flatten(), keras_trace[klayer].flatten(), s=0.2)\n",
    "#     min_x = min(np.amin(hls4ml_trace[layer]), np.amin(keras_trace[klayer]))\n",
    "#     max_x = max(np.amax(hls4ml_trace[layer]), np.amax(keras_trace[klayer]))\n",
    "#     plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "#     plt.xlabel('hls4ml {}'.format(layer))\n",
    "#     plt.ylabel('QKeras {}'.format(klayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "379c9632-898f-4b03-b29f-a93fe53b67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(B,H,W,Din)\n",
    "\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(Din):\n",
    "                x[i][h][w][d] = h + w + d\n",
    "\n",
    "q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1af3f7d-c35c-4f37-b7a4-6b66b5b26ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.]],\n",
       "\n",
       "        [[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.]],\n",
       "\n",
       "        [[2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.]],\n",
       "\n",
       "        [[3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.]],\n",
       "\n",
       "        [[4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dbe2ad5-96e3-4cd1-8491-d6778a43568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hmodel.predict(q_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "007f6c10-90ee-47e6-9c11-c91b22b17246",
   "metadata": {},
   "source": [
    "### Run HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b4a4e2-7250-469e-8ae4-0cbf6161dc8f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_model(keras_model,\n",
    "                  layer='layer_undef',\n",
    "                  strategy='Latency',\n",
    "                  io_type='io_stream',\n",
    "                  hls_backend='Vivado',\n",
    "                  fpga_part='xcu250-figd2104-2L-e',\n",
    "                  output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\n",
    "                 ):\n",
    "\n",
    "    yaml_config = hls4ml.backends.get_backend(hls_backend).create_initial_config(\n",
    "        part=fpga_part, \n",
    "        io_type=io_type,\n",
    "    )\n",
    "    # or whatever part you want to use\n",
    "    yaml_config['Backend'] = hls_backend\n",
    "\n",
    "    yaml_config['ProjectName'] = 'smartpixels'\n",
    "    config = hls4ml.utils.config_from_keras_model(keras_model, granularity='name', default_precision='fixed<{},{}>'.format(FXD_W, FXD_I))\n",
    "    config['LayerName']['q_input_1']['Precision']['result'] = 'fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    "    \n",
    "    config['Model']['Strategy'] = strategy\n",
    "    \n",
    "    yaml_config['HLSConfig'] = config\n",
    "\n",
    "    if io_type == 'io_stream' and hls_backend == 'Vivado':\n",
    "        hls4ml.model.optimizer.get_optimizer('vivado:fifo_depth_optimization').configure(profiling_fifo_depth=100_000)\n",
    "        yaml_config['HLSConfig']['Flows'] = ['vivado:fifo_depth_optimization']\n",
    "\n",
    "    yaml_config['KerasModel'] = keras_model\n",
    "    yaml_config['OutputDir'] = output_dir.format(hls_backend.lower(), layer.lower(), strategy.lower(), io_type.lower(), fpga_part.lower())\n",
    "\n",
    "    # At this point you should verify that the yaml matches the one you already have (check the output directory of the existing project)\n",
    "\n",
    "    # About 10 samples should be enough, don't put a lot since you'll wait **A LOT** of time to simulate through them\n",
    "    x = np.random.rand(B,H,W,Din)\n",
    "\n",
    "    for i in range(B):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                for d in range(Din):\n",
    "                    x[i][h][w][d] = h + w + d\n",
    "\n",
    "    q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(x).numpy()\n",
    "\n",
    "    #q_x = quantized_bits(FXD_W, FXD_I-1, 1, alpha=1)(np.random.rand(B,H,W,Din)).numpy() # or whatever the input is\n",
    "\n",
    "    from pathlib import Path\n",
    "    Path(yaml_config['OutputDir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # We need both samples and predictions passed to the testbench for cosim to do meaningful stuff\n",
    "\n",
    "    input_data = ''\n",
    "    for sample in q_x:\n",
    "        for val in sample.flatten():\n",
    "            input_data += str(val) + ' '\n",
    "        input_data += '\\n'\n",
    "\n",
    "    input_data_path = yaml_config['OutputDir'] + '/input_data.dat'\n",
    "\n",
    "    with open(input_data_path, 'w') as f:\n",
    "        f.write(input_data.rstrip())\n",
    "    yaml_config['InputData'] = input_data_path\n",
    "\n",
    "    y = keras_model.predict(q_x)\n",
    "    output_data = ''\n",
    "    for prediction in y:\n",
    "        for val in prediction.flatten():\n",
    "            output_data += str(val) + ' '\n",
    "        output_data += '\\n'\n",
    "\n",
    "    output_data_path = yaml_config['OutputDir'] + '/output_data.dat'\n",
    "    with open(output_data_path, 'w') as f:\n",
    "        f.write(output_data.rstrip())\n",
    "    yaml_config['OutputPredictions'] = output_data_path\n",
    "\n",
    "    model = hls4ml.converters.keras_to_hls(yaml_config)\n",
    "    model.write()\n",
    "\n",
    "    # reset=True will nuke any existing synthesis, use with care\n",
    "    report = model.build(csim=False, synth=True, cosim=True, validation=False, export=True, vsynth=True, reset=True)\n",
    "    #report = model.build(csim=False, synth=False, cosim=False, validation=False, export=False, vsynth=False, reset=False)\n",
    "    report.pop('CSimResults', None) # We don't care about this, and it spams the output\n",
    "    report.pop('CosimResults', None)\n",
    "    print(report) # Print hashmap\n",
    "    return report, fpga_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7eaed8-bd0f-4abd-a8d8-604081b7ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    return result.stdout, result.stderr\n",
    "\n",
    "def print_report(report, fpga_part = '?', vivado_version = '?', knobs = {}, hls = True, syn = True, cosim = True):\n",
    "    hls_results = report['CSynthesisReport']\n",
    "    syn_results = report['VivadoSynthReport']\n",
    "    cosim_results = report['CosimReport']\n",
    "    if hls:\n",
    "        print('-----------------------------------')\n",
    "        print('Vivado version: {}'.format(vivado_version))\n",
    "        print('FPGA part:      {}'.format(fpga_part))\n",
    "        print('Knobs:          {}'.format(knobs))\n",
    "        print('-----------------------------------')\n",
    "        print('HLS')\n",
    "        print('Target Clock Period:    {} ns'.format(hls_results['TargetClockPeriod']))\n",
    "        print('Estimated Clock Period: {} ns'.format(hls_results['EstimatedClockPeriod']))\n",
    "        print('Best/Worst Latency: {} / {}'.format(hls_results['BestLatency'], hls_results['WorstLatency']))\n",
    "        print('Interval Min/Max:   {} / {}'.format(hls_results['IntervalMin'], hls_results['IntervalMax']))\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(hls_results['BRAM_18K'], float(hls_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(hls_results['DSP'], float(hls_results['DSP'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(hls_results['FF'], float(hls_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(hls_results['LUT'], float(hls_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "        #print(\"URAM:                   {}, {} (Aval. {})\".format(hls_results['URAM'], int(hls_results['URAM'])*100.0/int(hls_results['AvailableURAM']), hls_results['AvailableURAM']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Synthesis')\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(syn_results['BRAM_18K'], float(syn_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(syn_results['DSP48E'], float(syn_results['DSP48E'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(syn_results['FF'], float(syn_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(syn_results['LUT'], float(syn_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Cosimulation')\n",
    "        print('Max/Min Latency:    {} / {}'.format(cosim_results['LatencyMax'], cosim_results['LatencyMin']))\n",
    "        print('Avg Latency:        {}'.format(cosim_results['LatencyAvg']))\n",
    "        print('Max/Min Interval:   {} / {}'.format(cosim_results['IntervalMax'], cosim_results['IntervalMin']))\n",
    "        print('Avg Interval:       {}'.format(cosim_results['IntervalAvg']))\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceec8e72-5a45-412b-a655-57b0d3c0d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = run_command('vivado -version')\n",
    "vivado_version = stdout.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b17a91a6-37d5-4874-96a0-d06b6db5faff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_HLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6de40a5-05c5-4dfd-a2b6-8bf8e6be257f",
   "metadata": {},
   "source": [
    "### Run synthesis for Alveo U250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d13bc4b4-3f05-4650-a969-95e6589ac93b",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_depthwise_conv2d, layer type: QDepthwiseConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 1]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/q_depthwise_conv2d/depthwise' defined at (most recent call last):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1035725/1890756911.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', \"if (RUN_HLS):\\n    report, fpga_part = convert_model(qmodel,                                    \\n                                      layer=LAYER,\\n                                      strategy=STRATEGY,\\n                                      io_type=IO_TYPE,\\n                                      hls_backend=BACKEND,\\n                                      fpga_part='xcu250-figd2104-2L-e',\\n                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\\n                                     )\\n\")\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2517, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1340, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_1035725/1244092923.py\", line 64, in convert_model\n      y = keras_model.predict(q_x)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/qconvolutional.py\", line 984, in call\n      outputs = tf.keras.backend.depthwise_conv2d(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/backend.py\", line 6318, in depthwise_conv2d\n      x = tf.compat.v1.nn.depthwise_conv2d(\nNode: 'model_1/q_depthwise_conv2d/depthwise'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=1}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=1,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng6{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=2,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=0,k4=1,k5=1,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng3{k11=2}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n\t [[{{node model_1/q_depthwise_conv2d/depthwise}}]] [Op:__inference_predict_function_398]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[34], line 64\u001b[0m, in \u001b[0;36mconvert_model\u001b[0;34m(keras_model, layer, strategy, io_type, hls_backend, fpga_part, output_dir)\u001b[0m\n\u001b[1;32m     61\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(input_data\u001b[38;5;241m.\u001b[39mrstrip())\n\u001b[1;32m     62\u001b[0m yaml_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputData\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_data_path\n\u001b[0;32m---> 64\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m y:\n",
      "File \u001b[0;32m~/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/q_depthwise_conv2d/depthwise' defined at (most recent call last):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1035725/1890756911.py\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', \"if (RUN_HLS):\\n    report, fpga_part = convert_model(qmodel,                                    \\n                                      layer=LAYER,\\n                                      strategy=STRATEGY,\\n                                      io_type=IO_TYPE,\\n                                      hls_backend=BACKEND,\\n                                      fpga_part='xcu250-figd2104-2L-e',\\n                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\\n                                     )\\n\")\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2517, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1340, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 2, in <module>\n    File \"/tmp/ipykernel_1035725/1244092923.py\", line 64, in convert_model\n      y = keras_model.predict(q_x)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/qkeras/qconvolutional.py\", line 984, in call\n      outputs = tf.keras.backend.depthwise_conv2d(\n    File \"/home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/keras/backend.py\", line 6318, in depthwise_conv2d\n      x = tf.compat.v1.nn.depthwise_conv2d(\nNode: 'model_1/q_depthwise_conv2d/depthwise'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine eng1{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=1}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng12{k5=1,k6=0,k7=1,k10=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=1,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng6{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=2,k4=2,k5=0,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng42{k2=0,k4=1,k5=1,k6=0,k7=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng3{k11=2}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n  Profiling failure on CUDNN engine eng4{}: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(4649): 'status'\n\t [[{{node model_1/q_depthwise_conv2d/depthwise}}]] [Op:__inference_predict_function_398]"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if (RUN_HLS):\n",
    "    report, fpga_part = convert_model(qmodel,                                    \n",
    "                                      layer=LAYER,\n",
    "                                      strategy=STRATEGY,\n",
    "                                      io_type=IO_TYPE,\n",
    "                                      hls_backend=BACKEND,\n",
    "                                      fpga_part='xcu250-figd2104-2L-e',\n",
    "                                      output_dir='{}_{}_{}_{}_{}_hls4ml_prj'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e80636-250f-452b-8b34-f48267654919",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (RUN_HLS):\n\u001b[0;32m----> 2\u001b[0m     print_report(\u001b[43mreport\u001b[49m,\n\u001b[1;32m      3\u001b[0m                  fpga_part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxcu250-figd2104-2L-e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                  vivado_version\u001b[38;5;241m=\u001b[39mvivado_version,\n\u001b[1;32m      5\u001b[0m                  knobs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m : BACKEND, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m :LAYER, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mio_type\u001b[39m\u001b[38;5;124m'\u001b[39m : IO_TYPE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m : STRATEGY}\n\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "if (RUN_HLS):\n",
    "    print_report(report,\n",
    "                 fpga_part='xcu250-figd2104-2L-e',\n",
    "                 vivado_version=vivado_version,\n",
    "                 knobs = {'backend' : BACKEND, 'layer' :LAYER, 'io_type' : IO_TYPE, 'strategy' : STRATEGY}\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39105976-e390-4fa5-9d2d-3825e1df1180",
   "metadata": {},
   "source": [
    "#### Previous results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cf624a1-a512-408b-8b7b-dfc0d763fb8f",
   "metadata": {},
   "source": [
    "##### `depthwise_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6de1736-7518-4f70-bb6b-e88dfc2e3c5a",
   "metadata": {},
   "source": [
    "```\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'depthwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.271 ns\n",
    "Best/Worst Latency: 5 / 6\n",
    "Interval Min/Max:   3 / 3\n",
    "BRAM_18K:           10, 0.2% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 721, 0.0% (Aval. 3456000)\n",
    "LUT:                39898, 2.3% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 1271, 0.0% (Aval. 3456000)\n",
    "LUT:                1628, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    6 / 6\n",
    "Avg Latency:        6.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a87b21-315d-4ff9-beb0-2e84bd82dafa",
   "metadata": {},
   "source": [
    "##### `pointwise_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b65250-b927-4cfb-a93f-cdfdd581177f",
   "metadata": {},
   "source": [
    "```\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'pointwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "Notes:          It uses conv2d\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.225 ns\n",
    "Best/Worst Latency: 59 / 60\n",
    "Interval Min/Max:   60 / 60\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 1151, 0.0% (Aval. 3456000)\n",
    "LUT:                1387, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 489, 0.0% (Aval. 3456000)\n",
    "LUT:                601, 0.0% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    60 / 60\n",
    "Avg Latency:        60.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Knobs:          {'backend': 'Vivado', 'layer': 'pointwise_conv2d', 'io_type': 'io_parallel', 'strategy': 'Latency'}\n",
    "Notes:          Custom pointwise, optimized\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 2.679 ns\n",
    "Best/Worst Latency: 4 / 5\n",
    "Interval Min/Max:   5 / 5\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 726, 0.0% (Aval. 3456000)\n",
    "LUT:                10091, 0.6% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           0, 0.0% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 377, 0.0% (Aval. 3456000)\n",
    "LUT:                867, 0.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    5 / 5\n",
    "Avg Latency:        5.0\n",
    "Max/Min Interval:   0 / 0\n",
    "Avg Interval:       0.0\n",
    "-----------------------------------\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56c776ec-8f89-43a0-b857-654c2e529734",
   "metadata": {},
   "source": [
    "##### `separable_conv2d`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3022d54a-347e-476d-aecf-efc72353d589",
   "metadata": {},
   "source": [
    "csim works, but HLS fails\n",
    "```\n",
    "ERROR: [HLS 200-70] Compilation errors found: In file included from firmware/smartpixels.cpp:1:\n",
    "firmware/smartpixels.cpp:35:2: error: no matching function for call to 'separable_conv_2d_cl'\n",
    " nnet::separable_conv_2d_cl<input_t, q_separable_conv2d_dw_out_t, result_t, config2>(q_input_1, layer2_out, d2, p2, z2, b2);\n",
    " ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "firmware/nnet_utils/nnet_sepconv2d_stream.h:122:6: note: candidate function [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2] not viable: no known conversion from 'input_t *' (aka 'ap_fixed<12, 11> *') to 'hls::stream<ap_fixed<12, 11, 5, 3, 0> > &' for 1st argument; \n",
    "void separable_conv_2d_cl(hls::stream<data_T> &data, hls::stream<res_T> &res,\n",
    "     ^\n",
    "firmware/nnet_utils/nnet_sepconv2d.h:51:6: note: candidate template ignored: substitution failure [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<12, 11, 5, 3, 0>, res_T = ap_fixed<12, 11, 5, 3, 0>, CONFIG_T = config2]\n",
    "void separable_conv_2d_cl(\n",
    "     ^\n",
    "1 error generated.\n",
    "Failed during preprocessing.\n",
    "    while executing\n",
    "\"source build_prj.tcl\"\n",
    "    (\"uplevel\" body line 1)\n",
    "    invoked from within\n",
    "\"uplevel \\#0 [list source $arg] \"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d4cf5be-9005-4237-bc70-a892908f1a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /home/xilinx/Vivado/2019.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/home/xilinx/Vivado/2019.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'russelld' on host 'scully.physics.ucsd.edu' (Linux_x86_64 version 4.18.0-348.12.2.el8_5.x86_64) on Wed Nov 29 18:25:47 PST 2023\n",
      "INFO: [HLS 200-10] In directory '/home/users/russelld/SepConv2D_hls4ml/vivado_depthwise_conv2d_latency_io_parallel_trace_hls4ml_prj'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Creating and opening project '/home/users/russelld/SepConv2D_hls4ml/vivado_depthwise_conv2d_latency_io_parallel_trace_hls4ml_prj/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Creating and opening solution '/home/users/russelld/SepConv2D_hls4ml/vivado_depthwise_conv2d_latency_io_parallel_trace_hls4ml_prj/myproject_prj/solution1'.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcu250-figd2104-2L-e'\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:33:80\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 1 issue(s) in file firmware/myproject.cpp\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&data type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&res type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&pointwise_biases type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&pointwise_weights type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&data type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&res type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&depthwise_biases type=complete dim=0' is not a valid pragma.\n",
      "ERROR: [HLS 200-70] '#pragma HLS ARRAY_PARTITION variable=&depthwise_weights type=complete dim=0' is not a valid pragma.\n",
      "Pragma processor failed: \n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Wed Nov 29 18:25:54 2023...\n",
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmodel.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1be8a-f987-43bd-95eb-72b9afe37657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
