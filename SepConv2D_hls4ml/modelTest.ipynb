{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d366d53b-37c2-4af5-bc61-14ed183b4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Choose the layer to test\n",
    "#\n",
    "#LAYER = 'depthwise_conv2d' # \n",
    "#LAYER = 'pointwise_conv2d'\n",
    "LAYER = 'separable_conv2d' # uses both depthwise and pointwise\n",
    "\n",
    "RUN_HLS = True\n",
    "IO_TYPE = 'io_parallel'\n",
    "STRATEGY = 'Latency'\n",
    "BACKEND = 'Vivado'\n",
    "\n",
    "H = 5    # Input height\n",
    "W = 6    # Input width\n",
    "Din = 1  # Input # of channels\n",
    "Fh = 3   # Kernel height\n",
    "Fw = 3   # Kernel width\n",
    "Dout = 2 # Kernel # of filters\n",
    "\n",
    "B = 1   # Test set batch size\n",
    "\n",
    "FXD_W = 12 # Fixed-point precision, word bit width\n",
    "FXD_I = 11 # Fixed-point precision, integer-part bit width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dd88be-425d-453a-9c14-82a72d4dafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:26:49.995248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from qkeras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41de8458-914a-4249-8ef8-e85d73f0d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ecb102-3af5-47a6-bb1c-cd1aa2e7f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = '/home/xilinx/Vivado/2019.1/bin:' + os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825c44d1-8a2e-4a72-90de-42fb1794aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateKerasModel(layer, input_shape, kernel_size, filters):\n",
    " \n",
    "    x_in = Input(input_shape, name='input_1')\n",
    "    if layer == 'depthwise_conv2d':\n",
    "        x_out = DepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif layer == 'pointwise_conv2d':\n",
    "        x_out = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=(1,1),\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            bias_initializer=tf.keras.initializers.Zeros(), # makes debugging easy\n",
    "            name='pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = SeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            name = 'separable_conv2d'\n",
    "    )(x_in)\n",
    "    kmodel = Model(inputs=x_in, outputs=x_out)\n",
    "    return kmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275eaf60-ad82-4e52-ae07-b0f3d4c2706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 3, 4, 2)          11        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:26:53.557664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.573262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.573621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.574076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 14:26:53.574689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.574992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.575312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.836607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.836792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.836940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 14:26:53.837074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1590 MB memory:  -> device: 0, name: NVIDIA GeForce GT 1030, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "kmodel = CreateKerasModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "kmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f95b2dd-cf21-4822-be16-7469486041b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateQKerasModel(type, input_shape, kernel_size, filters):\n",
    "    # # Generate the same random values\n",
    "    # import random\n",
    "    # import numpy as np\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    # random.seed(42)\n",
    "    # np.random.seed(42)\n",
    "    # tf.random.set_seed(42)\n",
    "    \n",
    "    x_in = Input(input_shape, name='q_input_1')\n",
    "    if type == 'depthwise_conv2d':\n",
    "        x_out = QDepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_depthwise_conv2d'\n",
    "        )(x_in)\n",
    "    elif type == 'pointwise_conv2d':\n",
    "        x_out = QConv2D(\n",
    "            kernel_size=(1,1), # 1x1 convolution\n",
    "            filters=filters,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            kernel_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_pointwise_conv2d'\n",
    "        )(x_in)\n",
    "    else:\n",
    "        x_out = QSeparableConv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            use_bias=False,\n",
    "            depthwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            pointwise_initializer=tf.keras.initializers.Ones(), # makes debugging easy\n",
    "            depthwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            pointwise_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            bias_quantizer=quantized_bits(FXD_W, FXD_I-1, 1, alpha=1),\n",
    "            name='q_separable_conv2d'\n",
    "        )(x_in)\n",
    "    \n",
    "    qkmodel = Model(inputs=x_in, outputs=x_out)\n",
    "    return qkmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b554dcb8-9cb3-4ca2-a04e-bf6a33581b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/russelld/micromamba/envs/sepConv2d/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_input_1 (InputLayer)      [(None, 5, 6, 1)]         0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepara  (None, 3, 4, 2)          11        \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qkmodel = CreateQKerasModel(LAYER, input_shape=(H,W,Din), kernel_size=(Fh, Fw), filters=Dout)\n",
    "qkmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41da87ca-3102-43f7-a9de-038000048069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/russelld/SepConv2D_hls4ml/Software/hls4ml/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml.utils\n",
    "import hls4ml.converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a083d3-c25a-401c-bd42-ee5f5258c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(qkmodel, granularity='name')\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc75240c-3852-4d25-9f3f-ac96a8e00e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: q_input_1, layer type: InputLayer, input shapes: [[None, 5, 6, 1]], output shape: [None, 5, 6, 1]\n",
      "Layer name: q_separable_conv2d, layer type: QSeparableConv2D, input shapes: [[None, 5, 6, 1]], output shape: [None, 3, 4, 2]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "config['LayerName']['q_input_1']['Precision']['result'] = 'fixed<{},{}>'.format(FXD_W, FXD_I)\n",
    "\n",
    "config['Model']['Strategy'] = STRATEGY\n",
    "#config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    qkmodel, \n",
    "    hls_config=config, \n",
    "    output_dir='hls4ml_prj', \n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    backend=BACKEND,\n",
    "    io_type=IO_TYPE\n",
    ")\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec785143-ece4-4629-8afa-5679085db5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = hls4ml.converters.keras_to_hls(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd9f6396-c4b6-463a-9331-2767109f4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /home/xilinx/Vivado/2019.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/home/xilinx/Vivado/2019.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'russelld' on host 'scully.physics.ucsd.edu' (Linux_x86_64 version 4.18.0-348.12.2.el8_5.x86_64) on Thu Dec 07 14:27:34 PST 2023\n",
      "INFO: [HLS 200-10] In directory '/home/users/russelld/SepConv2D_hls4ml/hls4ml_prj'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/users/russelld/SepConv2D_hls4ml/hls4ml_prj/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/users/russelld/SepConv2D_hls4ml/hls4ml_prj/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcu250-figd2104-2L-e'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "ERROR: [HLS 200-70] Compilation errors found: In file included from firmware/myproject.cpp:1:\n",
      "firmware/myproject.cpp:35:2: error: no matching function for call to 'separable_conv_2d_cl'\n",
      " nnet::separable_conv_2d_cl<input_t, q_separable_conv2d_dw_out_t, result_t, config2>(q_input_1, layer2_out, d2, p2, z2, b2);\n",
      " ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "firmware/nnet_utils/nnet_sepconv2d_stream.h:122:6: note: candidate function [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<16, 6, 5, 3, 0>, res_T = ap_fixed<16, 6, 5, 3, 0>, CONFIG_T = config2] not viable: no known conversion from 'input_t *' (aka 'ap_fixed<12, 11> *') to 'hls::stream<ap_fixed<12, 11, 5, 3, 0> > &' for 1st argument; \n",
      "void separable_conv_2d_cl(hls::stream<data_T> &data, hls::stream<res_T> &res,\n",
      "     ^\n",
      "firmware/nnet_utils/nnet_sepconv2d.h:63:6: note: candidate template ignored: substitution failure [with data_T = ap_fixed<12, 11, 5, 3, 0>, dw_res_T = ap_fixed<16, 6, 5, 3, 0>, res_T = ap_fixed<16, 6, 5, 3, 0>, CONFIG_T = config2]\n",
      "void separable_conv_2d_cl(\n",
      "     ^\n",
      "1 error generated.\n",
      "Failed during preprocessing.\n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Thu Dec  7 14:27:38 2023...\n",
      "CSynthesis report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc942a2-4313-4386-a89e-8c86daeb1dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4392f7e9-e607-4f61-ae50-ef58375c32d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/users/russelld/SepConv2D_hls4ml/Software/hls4ml/hls4ml/__init__.py'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hls4ml\n",
    "hls4ml.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3d5c6-4d2d-4845-be52-0c2c44c1bdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8750d2f-8708-41e6-8679-644c7986ad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
